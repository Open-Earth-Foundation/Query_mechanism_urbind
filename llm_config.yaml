orchestrator:
  model: "openai/gpt-5.2"
  temperature: 0.0
  context_bundle_name: "context_bundle.json"
  context_window_tokens: 400000
  input_token_reserve: 20000
sql_researcher:
  model: "openai/gpt-5.2"
  temperature: 0.0
  context_window_tokens: 400000
  input_token_reserve: 2000
  max_result_tokens: 100000
  pre_orchestrator_rounds: 2
markdown_researcher:
  model: "x-ai/grok-4.1-fast"
  temperature: 0.0
  context_window_tokens: 200000
  input_token_reserve: 10000
  max_chunk_tokens: 40000
  chunk_overlap_tokens: 2000
  max_workers: 4
  max_retries: 2
  retry_base_seconds: 0.8
  retry_max_seconds: 6.0
  request_backoff_base_seconds: 0.5
  request_backoff_max_seconds: 2.0
writer:
  model: "openai/gpt-5.2"
  temperature: 0.0
  context_window_tokens: 400000
  input_token_reserve: 20000
chat:
  model: "openai/gpt-5.2"
  temperature: 0.0
  context_window_tokens: 400000
  input_token_reserve: 20000
  max_history_messages: 24
assumptions_reviewer:
  model: "openai/gpt-5.2"
  temperature: 0.0
  max_output_tokens: 8000
vector_store:
  enabled: false
  chroma_persist_path: ".chroma"
  chroma_collection_name: "markdown_chunks"
  embedding_model: "text-embedding-3-large"
  embedding_chunk_tokens: 800
  embedding_chunk_overlap_tokens: 80
  table_row_group_max_rows: 25
  index_manifest_path: ".chroma/index_manifest.json"
openrouter_base_url: "https://openrouter.ai/api/v1"
enable_sql: false
