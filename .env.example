# OpenRouter API key
# Optional if users provide their own key via frontend input.
OPENROUTER_API_KEY=your_key_here

# Optional: enable SQL mode by default for pipeline scripts (true/false)
ENABLE_SQL=false

# Optional: Postgres source DB; when set, takes precedence over SOURCE_DB_PATH
DATABASE_URL=postgresql+psycopg://user:pass@localhost:5432/dbname

# Optional: SQLite source DB fallback path (used when DATABASE_URL is not set)
SOURCE_DB_PATH=data/source.db

# Optional: markdown directory used by scripts
MARKDOWN_DIR=documents

# Optional: output directory for run artifacts
RUNS_DIR=output

# Optional: log verbosity (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Optional: OpenRouter base URL override
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# FastAPI async run workers (optional)
API_RUN_WORKERS=2

# Context chat prompt cap (optional; lower reduces latency under ingress timeouts)
CHAT_PROMPT_TOKEN_CAP=250000

# Provider request timeout for context chat in seconds (optional)
CHAT_PROVIDER_TIMEOUT_SECONDS=50

# Optional comma-separated CORS origins for API (frontend dev hosts)
API_CORS_ORIGINS=http://127.0.0.1:3000,http://localhost:3000

# Optional config path used by API for model setup
LLM_CONFIG_PATH=llm_config.yaml

# Optional predefined city groups JSON path for API /api/v1/city-groups
CITY_GROUPS_PATH=backend/api/assets/city_groups.json

# Vector store indexing toggle (safe default false)
VECTOR_STORE_ENABLED=false

# Chroma persistence path and collection settings
CHROMA_PERSIST_PATH=.chroma
CHROMA_COLLECTION_NAME=markdown_chunks

# Embedding provider/model and chunking parameters
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_CHUNK_TOKENS=800
EMBEDDING_CHUNK_OVERLAP_TOKENS=80
TABLE_ROW_GROUP_MAX_ROWS=25

# Markdown researcher batching settings (applies in both standard and vector-store modes)
# - BATCH_MAX_CHUNKS is a hard safety cap per request.
# - BATCH_MAX_INPUT_TOKENS is optional; when empty, runtime uses an adaptive default.
# - BATCH_OVERHEAD_TOKENS reserves prompt/payload overhead in adaptive mode.
# - Adaptive default formula:
#   EMBEDDING_CHUNK_TOKENS * MARKDOWN_BATCH_MAX_CHUNKS + MARKDOWN_BATCH_OVERHEAD_TOKENS
#   (then clamped by markdown researcher model max-input limit when available).
# - With defaults this is: 800 * 4 + 600 = 3800 tokens.
MARKDOWN_BATCH_MAX_CHUNKS=4
MARKDOWN_BATCH_MAX_INPUT_TOKENS=
MARKDOWN_BATCH_OVERHEAD_TOKENS=600

# Retriever settings (used when VECTOR_STORE_ENABLED=true)
# - MAX_DISTANCE is the Chroma distance cutoff; smaller = stricter, larger = higher recall.
# - MAX_CHUNKS_PER_CITY_QUERY limits how many candidates we fetch from Chroma per (city × query).
#   Higher = more chances to find close matches (and more work); lower = faster but can miss evidence.
# - FALLBACK_MIN_CHUNKS_PER_CITY_QUERY is the per (city × query) minimum returned:
#   we first keep chunks that pass MAX_DISTANCE; if that yields too few, we top up with the next-best chunks
#   (above the cutoff) until we reach this minimum (or we run out of candidates).
# - MAX_CHUNKS_PER_CITY is a final per-city cap applied after merging all queries + neighbor expansion.
#   Use it only as a safety/latency knob; it can drop chunks if set too low.
# - CONTEXT_WINDOW vars control same-file neighbor expansion by chunk_index (table window is usually larger).
VECTOR_STORE_RETRIEVAL_MAX_DISTANCE=
VECTOR_STORE_RETRIEVAL_MAX_CHUNKS_PER_CITY_QUERY=100
VECTOR_STORE_RETRIEVAL_FALLBACK_MIN_CHUNKS_PER_CITY_QUERY=20
VECTOR_STORE_RETRIEVAL_MAX_CHUNKS_PER_CITY=
VECTOR_STORE_CONTEXT_WINDOW_CHUNKS=1
VECTOR_STORE_TABLE_CONTEXT_WINDOW_CHUNKS=2
VECTOR_STORE_AUTO_UPDATE_ON_RUN=false

# Manifest path tracking file_hash -> chunk_ids
INDEX_MANIFEST_PATH=.chroma/index_manifest.json
